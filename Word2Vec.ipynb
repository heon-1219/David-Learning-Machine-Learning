{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNKe1HYWuSknrBF07vrsy94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heon-1219/David-Learning-Machine-Learning/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import nltk as nltk\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "r_paEy_djwdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "303jbbdM2drc",
        "outputId": "b8762b46-9dfc-4a36-fae2-a88ed1a9cb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x780c45eb0f10>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNFvh2uo33F8",
        "outputId": "e09ef778-aed7-40cb-c55b-920650fd747c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing for .xml type\n",
        "\n",
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "#from .xml grab between <content> and </content>\n",
        "\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "#parsing to get rid of * sigh * types of stuff\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "#tokenization using NLTK for the input corpus\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "#get rid of period marks, make all words lowercase\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "    normalized_text.append(tokens)\n",
        "\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
        "\n",
        "print('total # of samples: {}'.format(len(result)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zklXL-n2gt6",
        "outputId": "daafc589-8163-490e-d798-ed3cdb80387d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total # of samples: 273424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print 3 samples\n",
        "\n",
        "for line in result[:3]:\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJWThMnS3dUN",
        "outputId": "92a50234-be89-4ba7-b121-b1b376d622fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training word2vec\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = Word2Vec(sentences = result, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
        "#vector_size -> dimension of embedded vector\n",
        "#window -> context window size\n",
        "#min_count -> minimum frequency for a word to be studied\n",
        "#workers -> # of processes for learning\n",
        "#sg -> 0 is CBOW, 1 is Skip-gram\n",
        "\n",
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hZSh0ez4nMc",
        "outputId": "bf79e7ea-c8bd-4b47-fc4f-77a1bd9e73a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8331930637359619), ('guy', 0.8183996677398682), ('lady', 0.7742761969566345), ('boy', 0.7625151872634888), ('girl', 0.7300701141357422), ('soldier', 0.7288089394569397), ('gentleman', 0.7087107300758362), ('kid', 0.7043598890304565), ('friend', 0.6633100509643555), ('poet', 0.6605149507522583)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.save_word2vec_format('eng_w2v') #save model\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") #model load"
      ],
      "metadata": {
        "id": "H4DJeG1356TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing models that are the most similar with man\n",
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ0quhDY6Bbf",
        "outputId": "429b34db-2327-4de2-9943-c8e7b6febcfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8331930637359619), ('guy', 0.8183996677398682), ('lady', 0.7742761969566345), ('boy', 0.7625151872634888), ('girl', 0.7300701141357422), ('soldier', 0.7288089394569397), ('gentleman', 0.7087107300758362), ('kid', 0.7043598890304565), ('friend', 0.6633100509643555), ('poet', 0.6605149507522583)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_model.most_similar(\"boy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bss_ieEE6JAv",
        "outputId": "335f5e8e-2f8f-4f7f-d80a-81d5574e064c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('girl', 0.9267131090164185), ('kid', 0.8587265014648438), ('lady', 0.8224789500236511), ('woman', 0.7993374466896057), ('man', 0.7625150680541992), ('baby', 0.7591347098350525), ('guy', 0.7246057987213135), ('brother', 0.7130074501037598), ('mary', 0.7108638286590576), ('soldier', 0.6995643377304077)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1zgiruC6qLa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}