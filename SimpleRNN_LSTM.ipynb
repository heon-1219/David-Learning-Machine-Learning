{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1BU+fSX54YCi490nITiNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heon-1219/David-Learning-Machine-Learning/blob/main/SimpleRNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dVCRWmumROL",
        "outputId": "3184a23f-640b-4c1c-e3cc-55ee52380f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, 5)\n"
          ]
        }
      ],
      "source": [
        "#This data will be used as input for the Simple RNN\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional\n",
        "\n",
        "#X train data\n",
        "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
        "train_X = np.array(train_X, dtype=np.float32)\n",
        "print(np.shape(train_X))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = SimpleRNN(3, return_sequences = True, return_state = True)\n",
        "# rnn = SimpleRNN(3, return_sequences = False, return_state = False); implicit\n",
        "# return sequences makes every hidden state visible.\n",
        "# return_state returns the last hidden state\n",
        "hidden_state, last_state = rnn(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-73Es197mc6E",
        "outputId": "8b0933ea-4346-49fe-b23c-df6fa07e55c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[[-0.44785845 -0.7553059   0.98803157]\n",
            "  [-0.99610585  0.5773123   0.98155165]\n",
            "  [-0.99831593 -0.40003398  0.22512957]\n",
            "  [-0.9827681  -0.01502109  0.93560565]]], shape: (1, 4, 3)\n",
            "last hidden state : [[-0.9827681  -0.01502109  0.93560565]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM Example\n",
        "\n",
        "lstm = LSTM(3, return_sequences = False, return_state = True)\n",
        "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))\n",
        "\n",
        "# unlike SimpleRNN, returns three values\n",
        "# unlike SimpleRNN, ZLSTM returns cell state as well."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-c99frjnYF2",
        "outputId": "95e8dbbb-ab84-4be8-b4e9-2f7e552f13b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[-0.13369696 -0.10939941  0.5197757 ]], shape: (1, 3)\n",
            "last hidden state : [[-0.13369696 -0.10939941  0.5197757 ]], shape: (1, 3)\n",
            "last cell state : [[-0.37118372 -0.1331717   1.0408454 ]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bidirectional(LSTM)\n",
        "\n",
        "k_init = tf.keras.initializers.Constant(value=0.1)\n",
        "b_init = tf.keras.initializers.Constant(value=0)\n",
        "r_init = tf.keras.initializers.Constant(value=0.1)\n",
        "\n",
        "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMLCAGzkt722",
        "outputId": "32ee9aeb-bcd3-478f-9c81-6f8d32a94e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
            "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
            "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Generation using RNN\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"\"\"A Horse Is Racing \\n\n",
        "His Words Are The Law\\n\n",
        "One Ill Word Asks Another\\n\"\"\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('size of the word set: %d' % vocab_size)\n",
        "\n",
        "print('integer index: \\n', tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StTmH4vLuFOk",
        "outputId": "6e12c4c5-0840-478e-f471-42ddd9d14b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the word set: 15\n",
            "integer index: \n",
            " {'a': 1, 'horse': 2, 'is': 3, 'racing': 4, 'his': 5, 'words': 6, 'are': 7, 'the': 8, 'law': 9, 'one': 10, 'ill': 11, 'word': 12, 'asks': 13, 'another': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for line in text.split('\\n'):\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('number of samples in learning process: %d' % len(sequences))\n",
        "print('\\n', sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK3b-aAZ6NFe",
        "outputId": "0710c307-9c7c-404e-88e0-e17f6ffafb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of samples in learning process: 11\n",
            "\n",
            " [[1, 2], [1, 2, 3], [1, 2, 3, 4], [5, 6], [5, 6, 7], [5, 6, 7, 8], [5, 6, 7, 8, 9], [10, 11], [10, 11, 12], [10, 11, 12, 13], [10, 11, 12, 13, 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding process\n",
        "\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print('longest sample : {}'.format(max_len))\n",
        "#longest sample #\n",
        "\n",
        "#for the size of the longest sample #, start embedding\n",
        "sequences = pad_sequences(sequences, maxlen = max_len, padding = 'pre')\n",
        "print('\\n', sequences)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "print(X)\n",
        "print('\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC7QpzFO61ZC",
        "outputId": "4f3ea7ee-ba23-43a1-8ebd-503849fcc6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longest sample : 5\n",
            "\n",
            " [[ 0  0  0  1  2]\n",
            " [ 0  0  1  2  3]\n",
            " [ 0  1  2  3  4]\n",
            " [ 0  0  0  5  6]\n",
            " [ 0  0  5  6  7]\n",
            " [ 0  5  6  7  8]\n",
            " [ 5  6  7  8  9]\n",
            " [ 0  0  0 10 11]\n",
            " [ 0  0 10 11 12]\n",
            " [ 0 10 11 12 13]\n",
            " [10 11 12 13 14]]\n",
            "[[ 0  0  0  1]\n",
            " [ 0  0  1  2]\n",
            " [ 0  1  2  3]\n",
            " [ 0  0  0  5]\n",
            " [ 0  0  5  6]\n",
            " [ 0  5  6  7]\n",
            " [ 5  6  7  8]\n",
            " [ 0  0  0 10]\n",
            " [ 0  0 10 11]\n",
            " [ 0 10 11 12]\n",
            " [10 11 12 13]]\n",
            "\n",
            " [ 2  3  4  6  7  8  9 11 12 13 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label is now separated, one-hot encoding starts now\n",
        "\n",
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCCM45ck7dLo",
        "outputId": "0252d34b-0d43-45b9-e43f-e3045d164139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training RNN model starts now\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
        "\n",
        "#use softmax to categorize, cross entropy for loss and epoch = 200\n",
        "\n",
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X, y, epochs = 400, verbose = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wu2ZS2K9C1o",
        "outputId": "eae5fb25-e29e-476a-a0e5-8bfeb82e2110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/1 - 1s - loss: 2.6797 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step\n",
            "Epoch 2/400\n",
            "1/1 - 0s - loss: 2.6706 - accuracy: 0.0909 - 18ms/epoch - 18ms/step\n",
            "Epoch 3/400\n",
            "1/1 - 0s - loss: 2.6614 - accuracy: 0.1818 - 13ms/epoch - 13ms/step\n",
            "Epoch 4/400\n",
            "1/1 - 0s - loss: 2.6519 - accuracy: 0.2727 - 9ms/epoch - 9ms/step\n",
            "Epoch 5/400\n",
            "1/1 - 0s - loss: 2.6423 - accuracy: 0.2727 - 8ms/epoch - 8ms/step\n",
            "Epoch 6/400\n",
            "1/1 - 0s - loss: 2.6324 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/400\n",
            "1/1 - 0s - loss: 2.6223 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/400\n",
            "1/1 - 0s - loss: 2.6119 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 9/400\n",
            "1/1 - 0s - loss: 2.6012 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 10/400\n",
            "1/1 - 0s - loss: 2.5901 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/400\n",
            "1/1 - 0s - loss: 2.5788 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 12/400\n",
            "1/1 - 0s - loss: 2.5670 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 13/400\n",
            "1/1 - 0s - loss: 2.5549 - accuracy: 0.2727 - 9ms/epoch - 9ms/step\n",
            "Epoch 14/400\n",
            "1/1 - 0s - loss: 2.5423 - accuracy: 0.2727 - 9ms/epoch - 9ms/step\n",
            "Epoch 15/400\n",
            "1/1 - 0s - loss: 2.5294 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 16/400\n",
            "1/1 - 0s - loss: 2.5160 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 17/400\n",
            "1/1 - 0s - loss: 2.5021 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 18/400\n",
            "1/1 - 0s - loss: 2.4879 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/400\n",
            "1/1 - 0s - loss: 2.4731 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 20/400\n",
            "1/1 - 0s - loss: 2.4579 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 21/400\n",
            "1/1 - 0s - loss: 2.4423 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 22/400\n",
            "1/1 - 0s - loss: 2.4262 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 23/400\n",
            "1/1 - 0s - loss: 2.4096 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 24/400\n",
            "1/1 - 0s - loss: 2.3926 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
            "Epoch 25/400\n",
            "1/1 - 0s - loss: 2.3752 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 26/400\n",
            "1/1 - 0s - loss: 2.3572 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 27/400\n",
            "1/1 - 0s - loss: 2.3389 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 28/400\n",
            "1/1 - 0s - loss: 2.3201 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 29/400\n",
            "1/1 - 0s - loss: 2.3008 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 30/400\n",
            "1/1 - 0s - loss: 2.2810 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 31/400\n",
            "1/1 - 0s - loss: 2.2608 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 32/400\n",
            "1/1 - 0s - loss: 2.2401 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 33/400\n",
            "1/1 - 0s - loss: 2.2189 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/400\n",
            "1/1 - 0s - loss: 2.1971 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 35/400\n",
            "1/1 - 0s - loss: 2.1748 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 36/400\n",
            "1/1 - 0s - loss: 2.1520 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 37/400\n",
            "1/1 - 0s - loss: 2.1286 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 38/400\n",
            "1/1 - 0s - loss: 2.1046 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 39/400\n",
            "1/1 - 0s - loss: 2.0802 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 40/400\n",
            "1/1 - 0s - loss: 2.0551 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 41/400\n",
            "1/1 - 0s - loss: 2.0296 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 42/400\n",
            "1/1 - 0s - loss: 2.0036 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 43/400\n",
            "1/1 - 0s - loss: 1.9772 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 44/400\n",
            "1/1 - 0s - loss: 1.9505 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 45/400\n",
            "1/1 - 0s - loss: 1.9234 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 46/400\n",
            "1/1 - 0s - loss: 1.8962 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 47/400\n",
            "1/1 - 0s - loss: 1.8688 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 48/400\n",
            "1/1 - 0s - loss: 1.8414 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 49/400\n",
            "1/1 - 0s - loss: 1.8140 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 50/400\n",
            "1/1 - 0s - loss: 1.7868 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 51/400\n",
            "1/1 - 0s - loss: 1.7597 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 52/400\n",
            "1/1 - 0s - loss: 1.7329 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 53/400\n",
            "1/1 - 0s - loss: 1.7065 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 54/400\n",
            "1/1 - 0s - loss: 1.6804 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 55/400\n",
            "1/1 - 0s - loss: 1.6547 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 56/400\n",
            "1/1 - 0s - loss: 1.6295 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 57/400\n",
            "1/1 - 0s - loss: 1.6047 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 58/400\n",
            "1/1 - 0s - loss: 1.5803 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 59/400\n",
            "1/1 - 0s - loss: 1.5563 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 60/400\n",
            "1/1 - 0s - loss: 1.5328 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 61/400\n",
            "1/1 - 0s - loss: 1.5096 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 62/400\n",
            "1/1 - 0s - loss: 1.4868 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 63/400\n",
            "1/1 - 0s - loss: 1.4643 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 64/400\n",
            "1/1 - 0s - loss: 1.4421 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 65/400\n",
            "1/1 - 0s - loss: 1.4201 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 66/400\n",
            "1/1 - 0s - loss: 1.3984 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 67/400\n",
            "1/1 - 0s - loss: 1.3770 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 68/400\n",
            "1/1 - 0s - loss: 1.3558 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 69/400\n",
            "1/1 - 0s - loss: 1.3349 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/400\n",
            "1/1 - 0s - loss: 1.3142 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 71/400\n",
            "1/1 - 0s - loss: 1.2937 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 72/400\n",
            "1/1 - 0s - loss: 1.2735 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 73/400\n",
            "1/1 - 0s - loss: 1.2535 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 74/400\n",
            "1/1 - 0s - loss: 1.2338 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 75/400\n",
            "1/1 - 0s - loss: 1.2143 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 76/400\n",
            "1/1 - 0s - loss: 1.1951 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 77/400\n",
            "1/1 - 0s - loss: 1.1761 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 78/400\n",
            "1/1 - 0s - loss: 1.1574 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 79/400\n",
            "1/1 - 0s - loss: 1.1389 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 80/400\n",
            "1/1 - 0s - loss: 1.1206 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 81/400\n",
            "1/1 - 0s - loss: 1.1026 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 82/400\n",
            "1/1 - 0s - loss: 1.0848 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
            "Epoch 83/400\n",
            "1/1 - 0s - loss: 1.0671 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 84/400\n",
            "1/1 - 0s - loss: 1.0497 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 85/400\n",
            "1/1 - 0s - loss: 1.0325 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 86/400\n",
            "1/1 - 0s - loss: 1.0155 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 87/400\n",
            "1/1 - 0s - loss: 0.9987 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n",
            "Epoch 88/400\n",
            "1/1 - 0s - loss: 0.9820 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 89/400\n",
            "1/1 - 0s - loss: 0.9656 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/400\n",
            "1/1 - 0s - loss: 0.9493 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 91/400\n",
            "1/1 - 0s - loss: 0.9332 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 92/400\n",
            "1/1 - 0s - loss: 0.9173 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 93/400\n",
            "1/1 - 0s - loss: 0.9017 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 94/400\n",
            "1/1 - 0s - loss: 0.8862 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 95/400\n",
            "1/1 - 0s - loss: 0.8709 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 96/400\n",
            "1/1 - 0s - loss: 0.8559 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 97/400\n",
            "1/1 - 0s - loss: 0.8410 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 98/400\n",
            "1/1 - 0s - loss: 0.8264 - accuracy: 0.9091 - 12ms/epoch - 12ms/step\n",
            "Epoch 99/400\n",
            "1/1 - 0s - loss: 0.8119 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 100/400\n",
            "1/1 - 0s - loss: 0.7976 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 101/400\n",
            "1/1 - 0s - loss: 0.7836 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
            "Epoch 102/400\n",
            "1/1 - 0s - loss: 0.7697 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 103/400\n",
            "1/1 - 0s - loss: 0.7561 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 104/400\n",
            "1/1 - 0s - loss: 0.7426 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 105/400\n",
            "1/1 - 0s - loss: 0.7293 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 106/400\n",
            "1/1 - 0s - loss: 0.7162 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 107/400\n",
            "1/1 - 0s - loss: 0.7033 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 108/400\n",
            "1/1 - 0s - loss: 0.6906 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 109/400\n",
            "1/1 - 0s - loss: 0.6781 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 110/400\n",
            "1/1 - 0s - loss: 0.6658 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 111/400\n",
            "1/1 - 0s - loss: 0.6537 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 112/400\n",
            "1/1 - 0s - loss: 0.6418 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 113/400\n",
            "1/1 - 0s - loss: 0.6300 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 114/400\n",
            "1/1 - 0s - loss: 0.6185 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 115/400\n",
            "1/1 - 0s - loss: 0.6072 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 116/400\n",
            "1/1 - 0s - loss: 0.5960 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 117/400\n",
            "1/1 - 0s - loss: 0.5851 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 118/400\n",
            "1/1 - 0s - loss: 0.5743 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 119/400\n",
            "1/1 - 0s - loss: 0.5638 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 120/400\n",
            "1/1 - 0s - loss: 0.5534 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 121/400\n",
            "1/1 - 0s - loss: 0.5433 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 122/400\n",
            "1/1 - 0s - loss: 0.5333 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 123/400\n",
            "1/1 - 0s - loss: 0.5235 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 124/400\n",
            "1/1 - 0s - loss: 0.5140 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 125/400\n",
            "1/1 - 0s - loss: 0.5046 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 126/400\n",
            "1/1 - 0s - loss: 0.4954 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 127/400\n",
            "1/1 - 0s - loss: 0.4864 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 128/400\n",
            "1/1 - 0s - loss: 0.4776 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 129/400\n",
            "1/1 - 0s - loss: 0.4690 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 130/400\n",
            "1/1 - 0s - loss: 0.4605 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 131/400\n",
            "1/1 - 0s - loss: 0.4523 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 132/400\n",
            "1/1 - 0s - loss: 0.4442 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 133/400\n",
            "1/1 - 0s - loss: 0.4362 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 134/400\n",
            "1/1 - 0s - loss: 0.4285 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 135/400\n",
            "1/1 - 0s - loss: 0.4209 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 136/400\n",
            "1/1 - 0s - loss: 0.4135 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 137/400\n",
            "1/1 - 0s - loss: 0.4062 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 138/400\n",
            "1/1 - 0s - loss: 0.3991 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 139/400\n",
            "1/1 - 0s - loss: 0.3922 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 140/400\n",
            "1/1 - 0s - loss: 0.3854 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 141/400\n",
            "1/1 - 0s - loss: 0.3787 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 142/400\n",
            "1/1 - 0s - loss: 0.3722 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 143/400\n",
            "1/1 - 0s - loss: 0.3658 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 144/400\n",
            "1/1 - 0s - loss: 0.3596 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 145/400\n",
            "1/1 - 0s - loss: 0.3535 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 146/400\n",
            "1/1 - 0s - loss: 0.3475 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 147/400\n",
            "1/1 - 0s - loss: 0.3416 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 148/400\n",
            "1/1 - 0s - loss: 0.3359 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 149/400\n",
            "1/1 - 0s - loss: 0.3303 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 150/400\n",
            "1/1 - 0s - loss: 0.3248 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 151/400\n",
            "1/1 - 0s - loss: 0.3194 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 152/400\n",
            "1/1 - 0s - loss: 0.3142 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 153/400\n",
            "1/1 - 0s - loss: 0.3090 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 154/400\n",
            "1/1 - 0s - loss: 0.3040 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 155/400\n",
            "1/1 - 0s - loss: 0.2990 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 156/400\n",
            "1/1 - 0s - loss: 0.2942 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 157/400\n",
            "1/1 - 0s - loss: 0.2894 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 158/400\n",
            "1/1 - 0s - loss: 0.2848 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 159/400\n",
            "1/1 - 0s - loss: 0.2802 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 160/400\n",
            "1/1 - 0s - loss: 0.2758 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 161/400\n",
            "1/1 - 0s - loss: 0.2714 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 162/400\n",
            "1/1 - 0s - loss: 0.2671 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 163/400\n",
            "1/1 - 0s - loss: 0.2629 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 164/400\n",
            "1/1 - 0s - loss: 0.2588 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 165/400\n",
            "1/1 - 0s - loss: 0.2547 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 166/400\n",
            "1/1 - 0s - loss: 0.2508 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 167/400\n",
            "1/1 - 0s - loss: 0.2469 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 168/400\n",
            "1/1 - 0s - loss: 0.2431 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 169/400\n",
            "1/1 - 0s - loss: 0.2393 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 170/400\n",
            "1/1 - 0s - loss: 0.2356 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 171/400\n",
            "1/1 - 0s - loss: 0.2320 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 172/400\n",
            "1/1 - 0s - loss: 0.2285 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 173/400\n",
            "1/1 - 0s - loss: 0.2250 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 174/400\n",
            "1/1 - 0s - loss: 0.2216 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 175/400\n",
            "1/1 - 0s - loss: 0.2183 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 176/400\n",
            "1/1 - 0s - loss: 0.2150 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 177/400\n",
            "1/1 - 0s - loss: 0.2118 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 178/400\n",
            "1/1 - 0s - loss: 0.2086 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 179/400\n",
            "1/1 - 0s - loss: 0.2055 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 180/400\n",
            "1/1 - 0s - loss: 0.2024 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 181/400\n",
            "1/1 - 0s - loss: 0.1994 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 182/400\n",
            "1/1 - 0s - loss: 0.1965 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 183/400\n",
            "1/1 - 0s - loss: 0.1936 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/400\n",
            "1/1 - 0s - loss: 0.1907 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 185/400\n",
            "1/1 - 0s - loss: 0.1879 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 186/400\n",
            "1/1 - 0s - loss: 0.1852 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 187/400\n",
            "1/1 - 0s - loss: 0.1825 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 188/400\n",
            "1/1 - 0s - loss: 0.1798 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 189/400\n",
            "1/1 - 0s - loss: 0.1772 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 190/400\n",
            "1/1 - 0s - loss: 0.1746 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 191/400\n",
            "1/1 - 0s - loss: 0.1721 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 192/400\n",
            "1/1 - 0s - loss: 0.1696 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 193/400\n",
            "1/1 - 0s - loss: 0.1671 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 194/400\n",
            "1/1 - 0s - loss: 0.1647 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 195/400\n",
            "1/1 - 0s - loss: 0.1624 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 196/400\n",
            "1/1 - 0s - loss: 0.1600 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 197/400\n",
            "1/1 - 0s - loss: 0.1577 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 198/400\n",
            "1/1 - 0s - loss: 0.1555 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 199/400\n",
            "1/1 - 0s - loss: 0.1532 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 200/400\n",
            "1/1 - 0s - loss: 0.1511 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 201/400\n",
            "1/1 - 0s - loss: 0.1489 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 202/400\n",
            "1/1 - 0s - loss: 0.1468 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 203/400\n",
            "1/1 - 0s - loss: 0.1447 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 204/400\n",
            "1/1 - 0s - loss: 0.1426 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 205/400\n",
            "1/1 - 0s - loss: 0.1406 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 206/400\n",
            "1/1 - 0s - loss: 0.1386 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 207/400\n",
            "1/1 - 0s - loss: 0.1367 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 208/400\n",
            "1/1 - 0s - loss: 0.1347 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 209/400\n",
            "1/1 - 0s - loss: 0.1328 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 210/400\n",
            "1/1 - 0s - loss: 0.1310 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 211/400\n",
            "1/1 - 0s - loss: 0.1291 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 212/400\n",
            "1/1 - 0s - loss: 0.1273 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 213/400\n",
            "1/1 - 0s - loss: 0.1256 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 214/400\n",
            "1/1 - 0s - loss: 0.1238 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 215/400\n",
            "1/1 - 0s - loss: 0.1221 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 216/400\n",
            "1/1 - 0s - loss: 0.1204 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 217/400\n",
            "1/1 - 0s - loss: 0.1187 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 218/400\n",
            "1/1 - 0s - loss: 0.1171 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 219/400\n",
            "1/1 - 0s - loss: 0.1154 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 220/400\n",
            "1/1 - 0s - loss: 0.1138 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 221/400\n",
            "1/1 - 0s - loss: 0.1123 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 222/400\n",
            "1/1 - 0s - loss: 0.1107 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 223/400\n",
            "1/1 - 0s - loss: 0.1092 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 224/400\n",
            "1/1 - 0s - loss: 0.1077 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 225/400\n",
            "1/1 - 0s - loss: 0.1062 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 226/400\n",
            "1/1 - 0s - loss: 0.1048 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 227/400\n",
            "1/1 - 0s - loss: 0.1034 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 228/400\n",
            "1/1 - 0s - loss: 0.1020 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 229/400\n",
            "1/1 - 0s - loss: 0.1006 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 230/400\n",
            "1/1 - 0s - loss: 0.0992 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 231/400\n",
            "1/1 - 0s - loss: 0.0979 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 232/400\n",
            "1/1 - 0s - loss: 0.0966 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 233/400\n",
            "1/1 - 0s - loss: 0.0953 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 234/400\n",
            "1/1 - 0s - loss: 0.0940 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 235/400\n",
            "1/1 - 0s - loss: 0.0928 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 236/400\n",
            "1/1 - 0s - loss: 0.0915 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 237/400\n",
            "1/1 - 0s - loss: 0.0903 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 238/400\n",
            "1/1 - 0s - loss: 0.0891 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 239/400\n",
            "1/1 - 0s - loss: 0.0880 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 240/400\n",
            "1/1 - 0s - loss: 0.0868 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 241/400\n",
            "1/1 - 0s - loss: 0.0857 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 242/400\n",
            "1/1 - 0s - loss: 0.0846 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 243/400\n",
            "1/1 - 0s - loss: 0.0835 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 244/400\n",
            "1/1 - 0s - loss: 0.0824 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 245/400\n",
            "1/1 - 0s - loss: 0.0813 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 246/400\n",
            "1/1 - 0s - loss: 0.0803 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 247/400\n",
            "1/1 - 0s - loss: 0.0792 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 248/400\n",
            "1/1 - 0s - loss: 0.0782 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 249/400\n",
            "1/1 - 0s - loss: 0.0772 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 250/400\n",
            "1/1 - 0s - loss: 0.0763 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 251/400\n",
            "1/1 - 0s - loss: 0.0753 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 252/400\n",
            "1/1 - 0s - loss: 0.0744 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 253/400\n",
            "1/1 - 0s - loss: 0.0734 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 254/400\n",
            "1/1 - 0s - loss: 0.0725 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 255/400\n",
            "1/1 - 0s - loss: 0.0716 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 256/400\n",
            "1/1 - 0s - loss: 0.0707 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 257/400\n",
            "1/1 - 0s - loss: 0.0699 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 258/400\n",
            "1/1 - 0s - loss: 0.0690 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 259/400\n",
            "1/1 - 0s - loss: 0.0682 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 260/400\n",
            "1/1 - 0s - loss: 0.0673 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 261/400\n",
            "1/1 - 0s - loss: 0.0665 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 262/400\n",
            "1/1 - 0s - loss: 0.0657 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 263/400\n",
            "1/1 - 0s - loss: 0.0649 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 264/400\n",
            "1/1 - 0s - loss: 0.0642 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 265/400\n",
            "1/1 - 0s - loss: 0.0634 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 266/400\n",
            "1/1 - 0s - loss: 0.0626 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 267/400\n",
            "1/1 - 0s - loss: 0.0619 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 268/400\n",
            "1/1 - 0s - loss: 0.0612 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 269/400\n",
            "1/1 - 0s - loss: 0.0605 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 270/400\n",
            "1/1 - 0s - loss: 0.0598 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 271/400\n",
            "1/1 - 0s - loss: 0.0591 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 272/400\n",
            "1/1 - 0s - loss: 0.0584 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 273/400\n",
            "1/1 - 0s - loss: 0.0577 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 274/400\n",
            "1/1 - 0s - loss: 0.0571 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 275/400\n",
            "1/1 - 0s - loss: 0.0564 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 276/400\n",
            "1/1 - 0s - loss: 0.0558 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 277/400\n",
            "1/1 - 0s - loss: 0.0552 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 278/400\n",
            "1/1 - 0s - loss: 0.0545 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 279/400\n",
            "1/1 - 0s - loss: 0.0539 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 280/400\n",
            "1/1 - 0s - loss: 0.0533 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 281/400\n",
            "1/1 - 0s - loss: 0.0528 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 282/400\n",
            "1/1 - 0s - loss: 0.0522 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 283/400\n",
            "1/1 - 0s - loss: 0.0516 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 284/400\n",
            "1/1 - 0s - loss: 0.0511 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 285/400\n",
            "1/1 - 0s - loss: 0.0505 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 286/400\n",
            "1/1 - 0s - loss: 0.0500 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 287/400\n",
            "1/1 - 0s - loss: 0.0494 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 288/400\n",
            "1/1 - 0s - loss: 0.0489 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 289/400\n",
            "1/1 - 0s - loss: 0.0484 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 290/400\n",
            "1/1 - 0s - loss: 0.0479 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 291/400\n",
            "1/1 - 0s - loss: 0.0474 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 292/400\n",
            "1/1 - 0s - loss: 0.0469 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 293/400\n",
            "1/1 - 0s - loss: 0.0464 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 294/400\n",
            "1/1 - 0s - loss: 0.0459 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 295/400\n",
            "1/1 - 0s - loss: 0.0454 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 296/400\n",
            "1/1 - 0s - loss: 0.0450 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 297/400\n",
            "1/1 - 0s - loss: 0.0445 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 298/400\n",
            "1/1 - 0s - loss: 0.0441 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 299/400\n",
            "1/1 - 0s - loss: 0.0436 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 300/400\n",
            "1/1 - 0s - loss: 0.0432 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 301/400\n",
            "1/1 - 0s - loss: 0.0428 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 302/400\n",
            "1/1 - 0s - loss: 0.0424 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 303/400\n",
            "1/1 - 0s - loss: 0.0419 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 304/400\n",
            "1/1 - 0s - loss: 0.0415 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 305/400\n",
            "1/1 - 0s - loss: 0.0411 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 306/400\n",
            "1/1 - 0s - loss: 0.0407 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 307/400\n",
            "1/1 - 0s - loss: 0.0403 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 308/400\n",
            "1/1 - 0s - loss: 0.0399 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 309/400\n",
            "1/1 - 0s - loss: 0.0396 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 310/400\n",
            "1/1 - 0s - loss: 0.0392 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 311/400\n",
            "1/1 - 0s - loss: 0.0388 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 312/400\n",
            "1/1 - 0s - loss: 0.0385 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 313/400\n",
            "1/1 - 0s - loss: 0.0381 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 314/400\n",
            "1/1 - 0s - loss: 0.0377 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 315/400\n",
            "1/1 - 0s - loss: 0.0374 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 316/400\n",
            "1/1 - 0s - loss: 0.0371 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 317/400\n",
            "1/1 - 0s - loss: 0.0367 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 318/400\n",
            "1/1 - 0s - loss: 0.0364 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 319/400\n",
            "1/1 - 0s - loss: 0.0360 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 320/400\n",
            "1/1 - 0s - loss: 0.0357 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 321/400\n",
            "1/1 - 0s - loss: 0.0354 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 322/400\n",
            "1/1 - 0s - loss: 0.0351 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 323/400\n",
            "1/1 - 0s - loss: 0.0348 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 324/400\n",
            "1/1 - 0s - loss: 0.0345 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 325/400\n",
            "1/1 - 0s - loss: 0.0342 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 326/400\n",
            "1/1 - 0s - loss: 0.0339 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 327/400\n",
            "1/1 - 0s - loss: 0.0336 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 328/400\n",
            "1/1 - 0s - loss: 0.0333 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 329/400\n",
            "1/1 - 0s - loss: 0.0330 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 330/400\n",
            "1/1 - 0s - loss: 0.0327 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 331/400\n",
            "1/1 - 0s - loss: 0.0324 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 332/400\n",
            "1/1 - 0s - loss: 0.0322 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 333/400\n",
            "1/1 - 0s - loss: 0.0319 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 334/400\n",
            "1/1 - 0s - loss: 0.0316 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 335/400\n",
            "1/1 - 0s - loss: 0.0314 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 336/400\n",
            "1/1 - 0s - loss: 0.0311 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 337/400\n",
            "1/1 - 0s - loss: 0.0308 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 338/400\n",
            "1/1 - 0s - loss: 0.0306 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 339/400\n",
            "1/1 - 0s - loss: 0.0303 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 340/400\n",
            "1/1 - 0s - loss: 0.0301 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 341/400\n",
            "1/1 - 0s - loss: 0.0298 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 342/400\n",
            "1/1 - 0s - loss: 0.0296 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 343/400\n",
            "1/1 - 0s - loss: 0.0294 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 344/400\n",
            "1/1 - 0s - loss: 0.0291 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 345/400\n",
            "1/1 - 0s - loss: 0.0289 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 346/400\n",
            "1/1 - 0s - loss: 0.0287 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 347/400\n",
            "1/1 - 0s - loss: 0.0284 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 348/400\n",
            "1/1 - 0s - loss: 0.0282 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 349/400\n",
            "1/1 - 0s - loss: 0.0280 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 350/400\n",
            "1/1 - 0s - loss: 0.0278 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 351/400\n",
            "1/1 - 0s - loss: 0.0276 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 352/400\n",
            "1/1 - 0s - loss: 0.0274 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 353/400\n",
            "1/1 - 0s - loss: 0.0272 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 354/400\n",
            "1/1 - 0s - loss: 0.0269 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 355/400\n",
            "1/1 - 0s - loss: 0.0267 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 356/400\n",
            "1/1 - 0s - loss: 0.0265 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 357/400\n",
            "1/1 - 0s - loss: 0.0263 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 358/400\n",
            "1/1 - 0s - loss: 0.0261 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 359/400\n",
            "1/1 - 0s - loss: 0.0259 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 360/400\n",
            "1/1 - 0s - loss: 0.0258 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 361/400\n",
            "1/1 - 0s - loss: 0.0256 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 362/400\n",
            "1/1 - 0s - loss: 0.0254 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 363/400\n",
            "1/1 - 0s - loss: 0.0252 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 364/400\n",
            "1/1 - 0s - loss: 0.0250 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 365/400\n",
            "1/1 - 0s - loss: 0.0248 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 366/400\n",
            "1/1 - 0s - loss: 0.0246 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 367/400\n",
            "1/1 - 0s - loss: 0.0245 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 368/400\n",
            "1/1 - 0s - loss: 0.0243 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 369/400\n",
            "1/1 - 0s - loss: 0.0241 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 370/400\n",
            "1/1 - 0s - loss: 0.0240 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 371/400\n",
            "1/1 - 0s - loss: 0.0238 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 372/400\n",
            "1/1 - 0s - loss: 0.0236 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 373/400\n",
            "1/1 - 0s - loss: 0.0235 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 374/400\n",
            "1/1 - 0s - loss: 0.0233 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 375/400\n",
            "1/1 - 0s - loss: 0.0231 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 376/400\n",
            "1/1 - 0s - loss: 0.0230 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 377/400\n",
            "1/1 - 0s - loss: 0.0228 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 378/400\n",
            "1/1 - 0s - loss: 0.0227 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 379/400\n",
            "1/1 - 0s - loss: 0.0225 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 380/400\n",
            "1/1 - 0s - loss: 0.0223 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 381/400\n",
            "1/1 - 0s - loss: 0.0222 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 382/400\n",
            "1/1 - 0s - loss: 0.0220 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 383/400\n",
            "1/1 - 0s - loss: 0.0219 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 384/400\n",
            "1/1 - 0s - loss: 0.0218 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 385/400\n",
            "1/1 - 0s - loss: 0.0216 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 386/400\n",
            "1/1 - 0s - loss: 0.0215 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 387/400\n",
            "1/1 - 0s - loss: 0.0213 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 388/400\n",
            "1/1 - 0s - loss: 0.0212 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 389/400\n",
            "1/1 - 0s - loss: 0.0210 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 390/400\n",
            "1/1 - 0s - loss: 0.0209 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 391/400\n",
            "1/1 - 0s - loss: 0.0208 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 392/400\n",
            "1/1 - 0s - loss: 0.0206 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 393/400\n",
            "1/1 - 0s - loss: 0.0205 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 394/400\n",
            "1/1 - 0s - loss: 0.0204 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 395/400\n",
            "1/1 - 0s - loss: 0.0202 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 396/400\n",
            "1/1 - 0s - loss: 0.0201 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 397/400\n",
            "1/1 - 0s - loss: 0.0200 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 398/400\n",
            "1/1 - 0s - loss: 0.0199 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 399/400\n",
            "1/1 - 0s - loss: 0.0197 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 400/400\n",
            "1/1 - 0s - loss: 0.0196 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7af14ee1ab90>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence generator for testing\n",
        "\n",
        "def sentence_generation(model, tokenizer, current_word, n):\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    #iterate n times\n",
        "    for _ in range(n):\n",
        "      encoded = tokenizer.texts_to_sequences(current_word)[0]\n",
        "      encoded = pad_sequences([encoded], maxlen = 5, padding = 'pre')\n",
        "      # for input X, predict Y, and save Y in result\n",
        "      result = model.predict(encoded, verbose=0)\n",
        "      result = np.argmax(result, axis=1)\n",
        "\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "        #if the current index matches a word in results\n",
        "        if index == result:\n",
        "          break\n",
        "\n",
        "      #add the word to current word\n",
        "      current_word = current_word + ' ' + word\n",
        "      #save the word to sentence\n",
        "      sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "qoVNzPK_89F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print results\n",
        "\n",
        "print(sentence_generation(model, tokenizer, 'The', 3))\n",
        "print(sentence_generation(model, tokenizer, 'His', 2))\n",
        "print(sentence_generation(model, tokenizer, 'words', 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWwiJ3iQ-0IX",
        "outputId": "bf0239ba-dfef-448f-8f52-6e83e596ea5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The words words words\n",
            "His words words\n",
            "words words words words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "\n",
        "f = open('11-0.txt', 'rb')\n",
        "sentences = []\n",
        "for sentence in f:\n",
        "  sentence = sentence.strip()\n",
        "  sentence = sentence.lower()\n",
        "  sentence = sentence.decode('ascii', 'ignore')\n",
        "\n",
        "  if len(sentence) > 0:\n",
        "    sentences.append(sentence)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "8fUhPC0XdStU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwHeCVHweD9r",
        "outputId": "cb69ed28-23d7-4bc2-a34e-145217ee7799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"*** start of the project gutenberg ebook alice's adventures in\", 'wonderland ***', '[illustration]', 'alices adventures in wonderland', 'by lewis carroll']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w1H_7speKB-",
        "outputId": "46dfe51c-4b88-4370-dd62-4cc2d5cdc5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"*** start of the project gutenberg ebook alice's adventures in\",\n",
              " 'wonderland ***',\n",
              " '[illustration]',\n",
              " 'alices adventures in wonderland',\n",
              " 'by lewis carroll']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = ''.join(sentences)\n",
        "print('total length of the text: %d' % len(total_data))\n",
        "\n",
        "print(total_data[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qjXj1IpeM8Z",
        "outputId": "ed1e5165-1404-4b11-d543-d650bfac23a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total length of the text: 137826\n",
            "*** start of the project gutenberg ebook alice's adventures inwonderland ***[illustration]alices adventures in wonderlandby lewis carrollthe millennium fulcrum edition 3.0contentschapter i.     down t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = sorted(list(set(total_data)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('size of the set: {}'. format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70R5o-W6eZPK",
        "outputId": "effa552e-fe86-4615-a111-8672f8d880d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the set: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print('set :', char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHVik7o8ezfV",
        "outputId": "ca7f247f-8947-4cb1-dc6e-22191ec78dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set : {' ': 0, '!': 1, \"'\": 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '0': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "metadata": {
        "id": "RJM4XjjcfJBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = 'appl'\n",
        "train_y = 'pple'"
      ],
      "metadata": {
        "id": "7X_8HNWufRRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60\n",
        "\n",
        "n_samples = int(np.floor((len(total_data)-1)/ seq_length))\n",
        "print('sample #: {}'.format(n_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8VDBz35ffFv",
        "outputId": "739988c3-4f9a-4b2e-df87-3b09ecc8b4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample #: 2297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "  X_sample = total_data[i * seq_length: (i+1) * seq_length]\n",
        "\n",
        "  X_encoded = [char_to_index[c] for c in X_sample]\n",
        "  train_X.append(X_encoded)\n",
        "\n",
        "  y_sample = total_data[i * seq_length + 1: (i+1) * seq_length + 1]\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)\n",
        "\n",
        "print('X 1st sample: ', train_X[0])\n",
        "print('y 1st sample: ', train_y[0])\n",
        "print('-'*50)\n",
        "print('X first sample decoding: ', [index_to_char[i] for i in train_X[0]])\n",
        "print('y first sample decoding: ', [index_to_char[i] for i in train_y[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbAq794wfqnL",
        "outputId": "34cf249c-06ce-4a5b-c8fc-5a19c4d6ffd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 1st sample:  [5, 5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0]\n",
            "y 1st sample:  [5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25]\n",
            "--------------------------------------------------\n",
            "X first sample decoding:  ['*', '*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ']\n",
            "y first sample decoding:  ['*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = to_categorical(train_X)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
        "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM, TimeDistributed\n",
        "\n",
        "hidden_units = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]),\n",
        "return_sequences = True))\n",
        "model.add(LSTM(hidden_units, return_sequences = True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation = 'softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_X, train_y, epochs = 80, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLZbd9JqgzMY",
        "outputId": "e21ff093-f68e-4f2e-8222-937736bc948f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X의 크기(shape) : (2297, 60, 43)\n",
            "train_y의 크기(shape) : (2297, 60, 43)\n",
            "Epoch 1/80\n",
            "72/72 - 45s - loss: 3.0557 - accuracy: 0.1717 - 45s/epoch - 621ms/step\n",
            "Epoch 2/80\n",
            "72/72 - 44s - loss: 2.7529 - accuracy: 0.2351 - 44s/epoch - 605ms/step\n",
            "Epoch 3/80\n",
            "72/72 - 47s - loss: 2.4237 - accuracy: 0.3195 - 47s/epoch - 655ms/step\n",
            "Epoch 4/80\n",
            "72/72 - 46s - loss: 2.2772 - accuracy: 0.3564 - 46s/epoch - 634ms/step\n",
            "Epoch 5/80\n",
            "72/72 - 36s - loss: 2.1738 - accuracy: 0.3845 - 36s/epoch - 502ms/step\n",
            "Epoch 6/80\n",
            "72/72 - 32s - loss: 2.0917 - accuracy: 0.4071 - 32s/epoch - 445ms/step\n",
            "Epoch 7/80\n",
            "72/72 - 34s - loss: 2.0137 - accuracy: 0.4258 - 34s/epoch - 478ms/step\n",
            "Epoch 8/80\n",
            "72/72 - 32s - loss: 1.9511 - accuracy: 0.4423 - 32s/epoch - 447ms/step\n",
            "Epoch 9/80\n",
            "72/72 - 33s - loss: 1.8967 - accuracy: 0.4552 - 33s/epoch - 463ms/step\n",
            "Epoch 10/80\n",
            "72/72 - 33s - loss: 1.8476 - accuracy: 0.4674 - 33s/epoch - 461ms/step\n",
            "Epoch 11/80\n",
            "72/72 - 33s - loss: 1.8039 - accuracy: 0.4797 - 33s/epoch - 452ms/step\n",
            "Epoch 12/80\n",
            "72/72 - 35s - loss: 1.7620 - accuracy: 0.4908 - 35s/epoch - 480ms/step\n",
            "Epoch 13/80\n",
            "72/72 - 33s - loss: 1.7209 - accuracy: 0.5031 - 33s/epoch - 460ms/step\n",
            "Epoch 14/80\n",
            "72/72 - 33s - loss: 1.6823 - accuracy: 0.5133 - 33s/epoch - 459ms/step\n",
            "Epoch 15/80\n",
            "72/72 - 33s - loss: 1.6457 - accuracy: 0.5236 - 33s/epoch - 462ms/step\n",
            "Epoch 16/80\n",
            "72/72 - 32s - loss: 1.6090 - accuracy: 0.5327 - 32s/epoch - 449ms/step\n",
            "Epoch 17/80\n",
            "72/72 - 33s - loss: 1.5752 - accuracy: 0.5419 - 33s/epoch - 460ms/step\n",
            "Epoch 18/80\n",
            "72/72 - 34s - loss: 1.5414 - accuracy: 0.5512 - 34s/epoch - 468ms/step\n",
            "Epoch 19/80\n",
            "72/72 - 32s - loss: 1.5091 - accuracy: 0.5607 - 32s/epoch - 450ms/step\n",
            "Epoch 20/80\n",
            "72/72 - 33s - loss: 1.4764 - accuracy: 0.5685 - 33s/epoch - 462ms/step\n",
            "Epoch 21/80\n",
            "72/72 - 33s - loss: 1.4460 - accuracy: 0.5779 - 33s/epoch - 452ms/step\n",
            "Epoch 22/80\n",
            "72/72 - 32s - loss: 1.4136 - accuracy: 0.5867 - 32s/epoch - 447ms/step\n",
            "Epoch 23/80\n",
            "72/72 - 33s - loss: 1.3799 - accuracy: 0.5960 - 33s/epoch - 459ms/step\n",
            "Epoch 24/80\n",
            "72/72 - 32s - loss: 1.3486 - accuracy: 0.6059 - 32s/epoch - 450ms/step\n",
            "Epoch 25/80\n",
            "72/72 - 32s - loss: 1.3141 - accuracy: 0.6153 - 32s/epoch - 443ms/step\n",
            "Epoch 26/80\n",
            "72/72 - 33s - loss: 1.2804 - accuracy: 0.6253 - 33s/epoch - 457ms/step\n",
            "Epoch 27/80\n",
            "72/72 - 33s - loss: 1.2503 - accuracy: 0.6336 - 33s/epoch - 457ms/step\n",
            "Epoch 28/80\n",
            "72/72 - 32s - loss: 1.2144 - accuracy: 0.6442 - 32s/epoch - 444ms/step\n",
            "Epoch 29/80\n",
            "72/72 - 33s - loss: 1.1757 - accuracy: 0.6552 - 33s/epoch - 454ms/step\n",
            "Epoch 30/80\n",
            "72/72 - 33s - loss: 1.1411 - accuracy: 0.6660 - 33s/epoch - 457ms/step\n",
            "Epoch 31/80\n",
            "72/72 - 32s - loss: 1.1047 - accuracy: 0.6764 - 32s/epoch - 441ms/step\n",
            "Epoch 32/80\n",
            "72/72 - 32s - loss: 1.0682 - accuracy: 0.6866 - 32s/epoch - 445ms/step\n",
            "Epoch 33/80\n",
            "72/72 - 33s - loss: 1.0348 - accuracy: 0.6972 - 33s/epoch - 461ms/step\n",
            "Epoch 34/80\n",
            "72/72 - 32s - loss: 0.9958 - accuracy: 0.7077 - 32s/epoch - 443ms/step\n",
            "Epoch 35/80\n",
            "72/72 - 32s - loss: 0.9598 - accuracy: 0.7203 - 32s/epoch - 445ms/step\n",
            "Epoch 36/80\n",
            "72/72 - 34s - loss: 0.9250 - accuracy: 0.7305 - 34s/epoch - 467ms/step\n",
            "Epoch 37/80\n",
            "72/72 - 32s - loss: 0.8873 - accuracy: 0.7422 - 32s/epoch - 444ms/step\n",
            "Epoch 38/80\n",
            "72/72 - 32s - loss: 0.8546 - accuracy: 0.7530 - 32s/epoch - 446ms/step\n",
            "Epoch 39/80\n",
            "72/72 - 34s - loss: 0.8188 - accuracy: 0.7629 - 34s/epoch - 468ms/step\n",
            "Epoch 40/80\n",
            "72/72 - 32s - loss: 0.7853 - accuracy: 0.7739 - 32s/epoch - 444ms/step\n",
            "Epoch 41/80\n",
            "72/72 - 32s - loss: 0.7520 - accuracy: 0.7849 - 32s/epoch - 447ms/step\n",
            "Epoch 42/80\n",
            "72/72 - 34s - loss: 0.7191 - accuracy: 0.7949 - 34s/epoch - 467ms/step\n",
            "Epoch 43/80\n",
            "72/72 - 32s - loss: 0.6841 - accuracy: 0.8071 - 32s/epoch - 446ms/step\n",
            "Epoch 44/80\n",
            "72/72 - 32s - loss: 0.6545 - accuracy: 0.8157 - 32s/epoch - 446ms/step\n",
            "Epoch 45/80\n",
            "72/72 - 34s - loss: 0.6247 - accuracy: 0.8261 - 34s/epoch - 468ms/step\n",
            "Epoch 46/80\n",
            "72/72 - 32s - loss: 0.5938 - accuracy: 0.8355 - 32s/epoch - 446ms/step\n",
            "Epoch 47/80\n",
            "72/72 - 43s - loss: 0.5667 - accuracy: 0.8451 - 43s/epoch - 593ms/step\n",
            "Epoch 48/80\n",
            "72/72 - 33s - loss: 0.5425 - accuracy: 0.8526 - 33s/epoch - 457ms/step\n",
            "Epoch 49/80\n",
            "72/72 - 34s - loss: 0.5170 - accuracy: 0.8595 - 34s/epoch - 466ms/step\n",
            "Epoch 50/80\n",
            "72/72 - 32s - loss: 0.4913 - accuracy: 0.8687 - 32s/epoch - 444ms/step\n",
            "Epoch 51/80\n",
            "72/72 - 32s - loss: 0.4645 - accuracy: 0.8773 - 32s/epoch - 447ms/step\n",
            "Epoch 52/80\n",
            "72/72 - 34s - loss: 0.4427 - accuracy: 0.8848 - 34s/epoch - 470ms/step\n",
            "Epoch 53/80\n",
            "72/72 - 32s - loss: 0.4194 - accuracy: 0.8920 - 32s/epoch - 444ms/step\n",
            "Epoch 54/80\n",
            "72/72 - 32s - loss: 0.3954 - accuracy: 0.9001 - 32s/epoch - 444ms/step\n",
            "Epoch 55/80\n",
            "72/72 - 34s - loss: 0.3784 - accuracy: 0.9052 - 34s/epoch - 469ms/step\n",
            "Epoch 56/80\n",
            "72/72 - 32s - loss: 0.3603 - accuracy: 0.9103 - 32s/epoch - 446ms/step\n",
            "Epoch 57/80\n",
            "72/72 - 32s - loss: 0.3392 - accuracy: 0.9176 - 32s/epoch - 441ms/step\n",
            "Epoch 58/80\n",
            "72/72 - 34s - loss: 0.3204 - accuracy: 0.9239 - 34s/epoch - 467ms/step\n",
            "Epoch 59/80\n",
            "72/72 - 32s - loss: 0.3052 - accuracy: 0.9281 - 32s/epoch - 444ms/step\n",
            "Epoch 60/80\n",
            "72/72 - 32s - loss: 0.2912 - accuracy: 0.9316 - 32s/epoch - 445ms/step\n",
            "Epoch 61/80\n",
            "72/72 - 33s - loss: 0.2755 - accuracy: 0.9362 - 33s/epoch - 462ms/step\n",
            "Epoch 62/80\n",
            "72/72 - 32s - loss: 0.2597 - accuracy: 0.9413 - 32s/epoch - 447ms/step\n",
            "Epoch 63/80\n",
            "72/72 - 32s - loss: 0.2468 - accuracy: 0.9444 - 32s/epoch - 446ms/step\n",
            "Epoch 64/80\n",
            "72/72 - 33s - loss: 0.2333 - accuracy: 0.9480 - 33s/epoch - 465ms/step\n",
            "Epoch 65/80\n",
            "72/72 - 32s - loss: 0.2226 - accuracy: 0.9508 - 32s/epoch - 447ms/step\n",
            "Epoch 66/80\n",
            "72/72 - 32s - loss: 0.2121 - accuracy: 0.9533 - 32s/epoch - 441ms/step\n",
            "Epoch 67/80\n",
            "72/72 - 33s - loss: 0.2048 - accuracy: 0.9546 - 33s/epoch - 454ms/step\n",
            "Epoch 68/80\n",
            "72/72 - 33s - loss: 0.1990 - accuracy: 0.9556 - 33s/epoch - 460ms/step\n",
            "Epoch 69/80\n",
            "72/72 - 32s - loss: 0.1930 - accuracy: 0.9565 - 32s/epoch - 444ms/step\n",
            "Epoch 70/80\n",
            "72/72 - 33s - loss: 0.1863 - accuracy: 0.9576 - 33s/epoch - 455ms/step\n",
            "Epoch 71/80\n",
            "72/72 - 33s - loss: 0.1815 - accuracy: 0.9583 - 33s/epoch - 460ms/step\n",
            "Epoch 72/80\n",
            "72/72 - 32s - loss: 0.1779 - accuracy: 0.9586 - 32s/epoch - 444ms/step\n",
            "Epoch 73/80\n",
            "72/72 - 32s - loss: 0.1741 - accuracy: 0.9595 - 32s/epoch - 449ms/step\n",
            "Epoch 74/80\n",
            "72/72 - 33s - loss: 0.1744 - accuracy: 0.9588 - 33s/epoch - 461ms/step\n",
            "Epoch 75/80\n",
            "72/72 - 32s - loss: 0.1696 - accuracy: 0.9596 - 32s/epoch - 445ms/step\n",
            "Epoch 76/80\n",
            "72/72 - 32s - loss: 0.1641 - accuracy: 0.9600 - 32s/epoch - 449ms/step\n",
            "Epoch 77/80\n",
            "72/72 - 34s - loss: 0.1606 - accuracy: 0.9608 - 34s/epoch - 466ms/step\n",
            "Epoch 78/80\n",
            "72/72 - 32s - loss: 0.1521 - accuracy: 0.9626 - 32s/epoch - 446ms/step\n",
            "Epoch 79/80\n",
            "72/72 - 33s - loss: 0.1461 - accuracy: 0.9635 - 33s/epoch - 452ms/step\n",
            "Epoch 80/80\n",
            "72/72 - 33s - loss: 0.1384 - accuracy: 0.9643 - 33s/epoch - 462ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a0f02ce3d90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, length):\n",
        "  ix = [np.random.randint(vocab_size)]\n",
        "\n",
        "  y_char = [index_to_char[ix[-1]]]\n",
        "  print(ix[-1], ' character', y_char[-1], 'is used to start prediction!')\n",
        "\n",
        "  X = np.zeros((1, length, vocab_size))\n",
        "\n",
        "  for i in range(length):\n",
        "\n",
        "    X[0][i][ix[-1]] = 1\n",
        "    print(index_to_char[ix[-1]], end = \"\")\n",
        "    ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "    y_char.append(index_to_char[ix[-1]])\n",
        "\n",
        "  return ('').join(y_char)"
      ],
      "metadata": {
        "id": "36Oiu9FniNyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentence_generation(model, 100)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Odnee9pjssO",
        "outputId": "77dc6f05-e8f2-4ec8-8f57-c3cfd0a4ab61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9  character 0 is used to start prediction!\n",
            "1/1 [==============================] - 1s 849ms/step\n",
            "1/1 [==============================] - 1s 831ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "0comfortable for the dormouse, thought alice; only, as its aslee, as she spoke uphe sharply she said,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now that RNN is trained, actual text generation begins.\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "raw_text = '''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''\n",
        "\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FsIiR_cpFfR",
        "outputId": "c2d3ebd5-eb79-49ca-c058-a2939fa348fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vocabulary creation\n",
        "\n",
        "char_vocab = sorted(list(set(raw_text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('char set: ', char_vocab)\n",
        "print('size of char set: {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZjK8iFXuLqz",
        "outputId": "a1562850-1d5e-4912-cd5b-3cec47144868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "char set:  [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "size of char set: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#integer indexing\n",
        "\n",
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXz_3sBFuZHY",
        "outputId": "8c0fc11b-f34a-46c8-ec4c-8c91a4585711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(raw_text)):\n",
        "  seq = raw_text[i-length:i]\n",
        "  sequences.append(seq)\n",
        "print('total # of samples: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXo73dZBuo-X",
        "outputId": "f62d0c9b-ef4b-474d-e362-205adb6b658a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total # of samples: 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kcIXpa2u8B3",
        "outputId": "01f0fc5d-b637-4eb6-ba58-dd8f5e7ed852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I get on wi',\n",
              " ' get on wit',\n",
              " 'get on with',\n",
              " 'et on with ',\n",
              " 't on with l',\n",
              " ' on with li',\n",
              " 'on with lif',\n",
              " 'n with life',\n",
              " ' with life ',\n",
              " 'with life a']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[30:45]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RuSWQ9pu-PQ",
        "outputId": "4757c6ee-8684-4272-b4ec-52b1ca0881b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mmer, I lik',\n",
              " 'mer, I like',\n",
              " 'er, I like ',\n",
              " 'r, I like t',\n",
              " ', I like to',\n",
              " ' I like to ',\n",
              " 'I like to c',\n",
              " ' like to co',\n",
              " 'like to con',\n",
              " 'ike to cont',\n",
              " 'ke to conte',\n",
              " 'e to contem',\n",
              " ' to contemp',\n",
              " 'to contempl',\n",
              " 'o contempla']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences = []\n",
        "for sequence in sequences: # getting 1 sample from the set each\n",
        "  encoded_sequence = [char_to_index[char] for char in sequence] #integer indexing for each char\n",
        "  encoded_sequences.append(encoded_sequence)"
      ],
      "metadata": {
        "id": "xljVsOcHvCU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDgwgHnDvQW1",
        "outputId": "bae67189-2ced-4379-dd4e-34cedbba27fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
              " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
              " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
              " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
              " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separating X and y\n",
        "\n",
        "encoded_sequences = np.array(encoded_sequences)\n",
        "\n",
        "X_data = encoded_sequences[:, :-1]\n",
        "y_data = encoded_sequences[:, -1]\n",
        "\n",
        "print(X_data[:5])\n",
        "print(y_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6frbViTvSJ1",
        "outputId": "eb5d2b4f-9046-44a8-b7a3-b1f73e82b1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  0 16 14 28  0 24 23  0 31]\n",
            " [ 0 16 14 28  0 24 23  0 31 18]\n",
            " [16 14 28  0 24 23  0 31 18 28]\n",
            " [14 28  0 24 23  0 31 18 28 17]\n",
            " [28  0 24 23  0 31 18 28 17  0]]\n",
            "[18 28 17  0 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encoding for bot X and y values\n",
        "\n",
        "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
        "X_data_one_hot = np.array(X_data_one_hot)\n",
        "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)\n",
        "\n",
        "print(X_data_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6D6TsUlvyk9",
        "outputId": "83d4512a-1cb0-41b6-fc81-9307ab5a8e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 10, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting from one-hot to hidden, then to presentation level.\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "hidden_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape = (X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_data_one_hot, y_data_one_hot, epochs = 100, verbose = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiV3fstXwBe7",
        "outputId": "aa44f74c-4814-427f-8bb9-cf9bb382756c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 - 3s - loss: 3.4728 - accuracy: 0.0915 - 3s/epoch - 225ms/step\n",
            "Epoch 2/100\n",
            "14/14 - 0s - loss: 3.3648 - accuracy: 0.1995 - 93ms/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "14/14 - 0s - loss: 3.0994 - accuracy: 0.1972 - 93ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "14/14 - 0s - loss: 3.0057 - accuracy: 0.1972 - 93ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "14/14 - 0s - loss: 2.9736 - accuracy: 0.1972 - 99ms/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "14/14 - 0s - loss: 2.9442 - accuracy: 0.1972 - 88ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "14/14 - 0s - loss: 2.9245 - accuracy: 0.1972 - 88ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "14/14 - 0s - loss: 2.9085 - accuracy: 0.1972 - 91ms/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "14/14 - 0s - loss: 2.8883 - accuracy: 0.1972 - 118ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "14/14 - 0s - loss: 2.8593 - accuracy: 0.1972 - 106ms/epoch - 8ms/step\n",
            "Epoch 11/100\n",
            "14/14 - 0s - loss: 2.8308 - accuracy: 0.2066 - 90ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "14/14 - 0s - loss: 2.7901 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "14/14 - 0s - loss: 2.7452 - accuracy: 0.2254 - 93ms/epoch - 7ms/step\n",
            "Epoch 14/100\n",
            "14/14 - 0s - loss: 2.6997 - accuracy: 0.2207 - 91ms/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "14/14 - 0s - loss: 2.6671 - accuracy: 0.2488 - 89ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "14/14 - 0s - loss: 2.6202 - accuracy: 0.2441 - 93ms/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "14/14 - 0s - loss: 2.6046 - accuracy: 0.2559 - 91ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "14/14 - 0s - loss: 2.5666 - accuracy: 0.2488 - 88ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "14/14 - 0s - loss: 2.5016 - accuracy: 0.2582 - 106ms/epoch - 8ms/step\n",
            "Epoch 20/100\n",
            "14/14 - 0s - loss: 2.4600 - accuracy: 0.2981 - 118ms/epoch - 8ms/step\n",
            "Epoch 21/100\n",
            "14/14 - 0s - loss: 2.4060 - accuracy: 0.3169 - 87ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "14/14 - 0s - loss: 2.3645 - accuracy: 0.3005 - 92ms/epoch - 7ms/step\n",
            "Epoch 23/100\n",
            "14/14 - 0s - loss: 2.3247 - accuracy: 0.3216 - 90ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "14/14 - 0s - loss: 2.2891 - accuracy: 0.3451 - 88ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "14/14 - 0s - loss: 2.2370 - accuracy: 0.3216 - 86ms/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "14/14 - 0s - loss: 2.1961 - accuracy: 0.3873 - 95ms/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "14/14 - 0s - loss: 2.1426 - accuracy: 0.3944 - 85ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "14/14 - 0s - loss: 2.0981 - accuracy: 0.3732 - 88ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "14/14 - 0s - loss: 2.0439 - accuracy: 0.4272 - 88ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "14/14 - 0s - loss: 1.9982 - accuracy: 0.4460 - 132ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "14/14 - 0s - loss: 1.9582 - accuracy: 0.4671 - 90ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "14/14 - 0s - loss: 1.9135 - accuracy: 0.4695 - 100ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "14/14 - 0s - loss: 1.8654 - accuracy: 0.4742 - 97ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "14/14 - 0s - loss: 1.8231 - accuracy: 0.5117 - 88ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "14/14 - 0s - loss: 1.7593 - accuracy: 0.5188 - 89ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "14/14 - 0s - loss: 1.7200 - accuracy: 0.5376 - 92ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "14/14 - 0s - loss: 1.6801 - accuracy: 0.5446 - 87ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "14/14 - 0s - loss: 1.6404 - accuracy: 0.5634 - 89ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "14/14 - 0s - loss: 1.6001 - accuracy: 0.5822 - 91ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "14/14 - 0s - loss: 1.5685 - accuracy: 0.5915 - 123ms/epoch - 9ms/step\n",
            "Epoch 41/100\n",
            "14/14 - 0s - loss: 1.5356 - accuracy: 0.6009 - 98ms/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "14/14 - 0s - loss: 1.4842 - accuracy: 0.6221 - 91ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "14/14 - 0s - loss: 1.4447 - accuracy: 0.6362 - 97ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "14/14 - 0s - loss: 1.4032 - accuracy: 0.6362 - 91ms/epoch - 7ms/step\n",
            "Epoch 45/100\n",
            "14/14 - 0s - loss: 1.3848 - accuracy: 0.6596 - 91ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "14/14 - 0s - loss: 1.3425 - accuracy: 0.6714 - 97ms/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "14/14 - 0s - loss: 1.3068 - accuracy: 0.6620 - 97ms/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "14/14 - 0s - loss: 1.2578 - accuracy: 0.7136 - 99ms/epoch - 7ms/step\n",
            "Epoch 49/100\n",
            "14/14 - 0s - loss: 1.2402 - accuracy: 0.6925 - 111ms/epoch - 8ms/step\n",
            "Epoch 50/100\n",
            "14/14 - 0s - loss: 1.2062 - accuracy: 0.7160 - 114ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "14/14 - 0s - loss: 1.1711 - accuracy: 0.7300 - 98ms/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "14/14 - 0s - loss: 1.1291 - accuracy: 0.7394 - 93ms/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "14/14 - 0s - loss: 1.1053 - accuracy: 0.7418 - 102ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "14/14 - 0s - loss: 1.0597 - accuracy: 0.7653 - 92ms/epoch - 7ms/step\n",
            "Epoch 55/100\n",
            "14/14 - 0s - loss: 1.0315 - accuracy: 0.7535 - 93ms/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "14/14 - 0s - loss: 1.0042 - accuracy: 0.7887 - 92ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "14/14 - 0s - loss: 1.0018 - accuracy: 0.7653 - 88ms/epoch - 6ms/step\n",
            "Epoch 58/100\n",
            "14/14 - 0s - loss: 0.9552 - accuracy: 0.7934 - 88ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "14/14 - 0s - loss: 0.9190 - accuracy: 0.7934 - 108ms/epoch - 8ms/step\n",
            "Epoch 60/100\n",
            "14/14 - 0s - loss: 0.8949 - accuracy: 0.8099 - 108ms/epoch - 8ms/step\n",
            "Epoch 61/100\n",
            "14/14 - 0s - loss: 0.8722 - accuracy: 0.8122 - 102ms/epoch - 7ms/step\n",
            "Epoch 62/100\n",
            "14/14 - 0s - loss: 0.8355 - accuracy: 0.8263 - 99ms/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "14/14 - 0s - loss: 0.8117 - accuracy: 0.8286 - 97ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "14/14 - 0s - loss: 0.7940 - accuracy: 0.8310 - 87ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "14/14 - 0s - loss: 0.7736 - accuracy: 0.8451 - 93ms/epoch - 7ms/step\n",
            "Epoch 66/100\n",
            "14/14 - 0s - loss: 0.7426 - accuracy: 0.8615 - 87ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "14/14 - 0s - loss: 0.7171 - accuracy: 0.8615 - 92ms/epoch - 7ms/step\n",
            "Epoch 68/100\n",
            "14/14 - 0s - loss: 0.6982 - accuracy: 0.8732 - 90ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "14/14 - 0s - loss: 0.6877 - accuracy: 0.8779 - 103ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "14/14 - 0s - loss: 0.6658 - accuracy: 0.8850 - 97ms/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "14/14 - 0s - loss: 0.6486 - accuracy: 0.8779 - 105ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "14/14 - 0s - loss: 0.6260 - accuracy: 0.8803 - 92ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "14/14 - 0s - loss: 0.6054 - accuracy: 0.8897 - 101ms/epoch - 7ms/step\n",
            "Epoch 74/100\n",
            "14/14 - 0s - loss: 0.5841 - accuracy: 0.8920 - 90ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "14/14 - 0s - loss: 0.5702 - accuracy: 0.9014 - 91ms/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "14/14 - 0s - loss: 0.5395 - accuracy: 0.9085 - 98ms/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "14/14 - 0s - loss: 0.5432 - accuracy: 0.9131 - 94ms/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "14/14 - 0s - loss: 0.5148 - accuracy: 0.9178 - 90ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "14/14 - 0s - loss: 0.5015 - accuracy: 0.9178 - 112ms/epoch - 8ms/step\n",
            "Epoch 80/100\n",
            "14/14 - 0s - loss: 0.4876 - accuracy: 0.9272 - 97ms/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "14/14 - 0s - loss: 0.4806 - accuracy: 0.9202 - 103ms/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "14/14 - 0s - loss: 0.4570 - accuracy: 0.9366 - 93ms/epoch - 7ms/step\n",
            "Epoch 83/100\n",
            "14/14 - 0s - loss: 0.4440 - accuracy: 0.9366 - 100ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "14/14 - 0s - loss: 0.4337 - accuracy: 0.9343 - 90ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "14/14 - 0s - loss: 0.4108 - accuracy: 0.9460 - 90ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "14/14 - 0s - loss: 0.4072 - accuracy: 0.9460 - 95ms/epoch - 7ms/step\n",
            "Epoch 87/100\n",
            "14/14 - 0s - loss: 0.3930 - accuracy: 0.9484 - 93ms/epoch - 7ms/step\n",
            "Epoch 88/100\n",
            "14/14 - 0s - loss: 0.3841 - accuracy: 0.9507 - 91ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "14/14 - 0s - loss: 0.3783 - accuracy: 0.9484 - 119ms/epoch - 8ms/step\n",
            "Epoch 90/100\n",
            "14/14 - 0s - loss: 0.3624 - accuracy: 0.9507 - 101ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "14/14 - 0s - loss: 0.3468 - accuracy: 0.9577 - 104ms/epoch - 7ms/step\n",
            "Epoch 92/100\n",
            "14/14 - 0s - loss: 0.3433 - accuracy: 0.9531 - 98ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "14/14 - 0s - loss: 0.3295 - accuracy: 0.9671 - 96ms/epoch - 7ms/step\n",
            "Epoch 94/100\n",
            "14/14 - 0s - loss: 0.3197 - accuracy: 0.9671 - 93ms/epoch - 7ms/step\n",
            "Epoch 95/100\n",
            "14/14 - 0s - loss: 0.3100 - accuracy: 0.9624 - 90ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "14/14 - 0s - loss: 0.3061 - accuracy: 0.9671 - 91ms/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "14/14 - 0s - loss: 0.2998 - accuracy: 0.9671 - 99ms/epoch - 7ms/step\n",
            "Epoch 98/100\n",
            "14/14 - 0s - loss: 0.2852 - accuracy: 0.9765 - 95ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "14/14 - 0s - loss: 0.2765 - accuracy: 0.9742 - 123ms/epoch - 9ms/step\n",
            "Epoch 100/100\n",
            "14/14 - 0s - loss: 0.2642 - accuracy: 0.9718 - 98ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a0efcdc9810>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence generation start\n",
        "\n",
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "\n",
        "  init_text = seed_text\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = [char_to_index[char] for char in seed_text] #current sequence integer encoding\n",
        "    encoded = pad_sequences([encoded], maxlen = seq_length, padding = 'pre') #padding\n",
        "    encoded = to_categorical(encoded, num_classes = len(char_to_index)) #one-hot encoding\n",
        "\n",
        "#for current X predict y and save to results\n",
        "\n",
        "    result = model.predict(encoded, verbose = 0)\n",
        "    result = np.argmax(result, axis = 1)\n",
        "\n",
        "    for char, index in char_to_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    #current sequence + expected\n",
        "    seed_text = seed_text + char\n",
        "    #save to the current sentence\n",
        "    sentence = sentence + char\n",
        "\n",
        "  # when next n-times of prediction is done, return the sentence.\n",
        "  sentence = init_text + sentence\n",
        "  return sentence\n"
      ],
      "metadata": {
        "id": "hIiV-zQ_xIgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w',80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj3hIsqYzA5j",
        "outputId": "df966b19-cff7-4568-f5c0-ad3b844ccce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with lofe aane mor  indg saade beorr  Bt wht oo lorsm min t aadng trm m ,inddgane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TnjTpqJXzFrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}